# ğŸ›¡ï¸ Network Security â€“ Phishing URL Detection

A machine learningâ€“powered phishing website detection system with a full end-to-end pipeline:

- Automated data ingestion, validation, transformation, training  
- Artifact tracking (every training run is saved with timestamps)  
- Model deployment using Docker + AWS + GitHub Actions (CI/CD)  
- Simple web app to check if a URL is phishing or legitimate  

---

## ğŸš€ Features
- ğŸ”„ Modular ML pipeline (ingestion â†’ validation â†’ transformation â†’ training)  
- ğŸ“¦ Artifacts saved for every run (datasets, reports, models, transformers)  
- âœ… Data validation with schema checks & drift detection  
- ğŸ“Š MLflow tracking for experiments  
- ğŸ³ Dockerized deployment (AWS ECR + ECS/self-hosted runner)  
- ğŸŒ Flask/FastAPI app with web UI + API endpoints  
- â˜ï¸ AWS S3 sync support for data & models  
- ğŸ—„ï¸ MongoDB integration for storing predictions/data  

---
<img width="1602" height="757" alt="image" src="https://github.com/user-attachments/assets/7c3c3e15-3df6-4442-a7c0-ccede3fd273d" />

<img width="1606" height="756" alt="image" src="https://github.com/user-attachments/assets/274a9f19-98c8-4a6f-a677-4768cf82167f" />


## ğŸ—ï¸ Project Structure
```bash
networksecurity/
â”‚â”€â”€ components/             # Core ML pipeline components
â”‚   â”‚â”€â”€ data_ingestion.py
â”‚   â”‚â”€â”€ data_validation.py
â”‚   â”‚â”€â”€ data_transformation.py
â”‚   â”‚â”€â”€ model_trainer.py
â”‚   â”‚â”€â”€ model_evaluation.py
â”‚
â”‚â”€â”€ pipeline/               # Orchestration of training & prediction pipelines
â”‚   â”‚â”€â”€ training_pipeline.py
â”‚   â”‚â”€â”€ prediction_pipeline.py
â”‚
â”‚â”€â”€ entity/                 # Config and artifact entity definitions
â”‚   â”‚â”€â”€ config_entity.py
â”‚   â”‚â”€â”€ artifact_entity.py
â”‚
â”‚â”€â”€ utils/                  # Helper utilities (ML + general)
â”‚   â”‚â”€â”€ __init__.py
â”‚   â”‚â”€â”€ common.py
â”‚
â”‚â”€â”€ cloud/                  # AWS / cloud syncer
â”‚   â”‚â”€â”€ s3_syncer.py
â”‚
â”‚â”€â”€ exception/              # Custom exceptions
â”‚   â”‚â”€â”€ exception.py
â”‚
â”‚â”€â”€ logging/                # Central logging module
â”‚   â”‚â”€â”€ logger.py
â”‚
â”‚â”€â”€ tests/                  # Unit & integration tests
â”‚   â”‚â”€â”€ test_ingestion.py
â”‚   â”‚â”€â”€ test_transformation.py
â”‚   â”‚â”€â”€ test_training.py
â”‚
â”‚â”€â”€ notebooks/              # Jupyter notebooks for EDA & experiments
â”‚   â”‚â”€â”€ 01_data_exploration.ipynb
â”‚   â”‚â”€â”€ 02_model_baseline.ipynb
â”‚   â”‚â”€â”€ 03_feature_engineering.ipynb
â”‚
â”‚â”€â”€ configs/                # YAML/JSON config files
â”‚   â”‚â”€â”€ schema.yaml
â”‚   â”‚â”€â”€ model_config.yaml
â”‚
â”‚â”€â”€ scripts/                # Handy shell/python scripts
â”‚   â”‚â”€â”€ run_pipeline.sh
â”‚   â”‚â”€â”€ deploy.sh
â”‚
â”‚â”€â”€ .github/workflows/      # CI/CD workflows (GitHub Actions)
â”‚   â”‚â”€â”€ ci-cd.yml
â”‚
â”‚â”€â”€ templates/              # Web UI (HTML templates)
â”‚   â”‚â”€â”€ home.html
â”‚   â”‚â”€â”€ result.html
â”‚
â”‚â”€â”€ Artifacts/              # Timestamped training outputs
â”‚â”€â”€ final_model/            # Production-ready model + preprocessor
â”‚â”€â”€ prediction_output/      # Predictions on new data
â”‚
â”‚â”€â”€ requirements.txt        # Project dependencies
â”‚â”€â”€ Dockerfile              # Container definition
â”‚â”€â”€ docker-compose.yml      # Multi-container setup (optional)
â”‚â”€â”€ setup.py                # Installable package setup
â”‚â”€â”€ app.py                  # Web app entry point (Flask/FastAPI)
â”‚â”€â”€ main.py                 # Training entry point
â”‚â”€â”€ README.md               # Project documentation
```

---

## âš™ï¸ Installation & Setup

### 1. Clone the Repository
```bash
git clone https://github.com/ShubhamJadhav03/networksecurity.git
cd networksecurity
```

### 2. Create Virtual Environment & Install Dependencies
```bash
python -m venv env
source env/bin/activate   # On Windows: env\Scripts\activate
pip install -r requirements.txt
```

### 3. Run Training Pipeline
```bash
python main.py
```
This will:
- Ingest and validate dataset (`Network_Data/phisingData.csv`)  
- Transform data and save preprocessing pipeline  
- Train ML model and save it into `final_model/`  

### 4. Run Web Application
```bash
python app.py
```
Then open your browser at [http://localhost:8080](http://localhost:8080) to test URLs.

---

## ğŸ³ Docker Deployment
```bash
docker build -t networksecurity .
docker run -p 8080:8080 networksecurity
```

---

## ğŸ”„ CI/CD (GitHub Actions + AWS)
On push to `main` branch:
- Runs integration checks  
- Builds Docker image & pushes to AWS ECR  
- Deploys updated container on server (self-hosted runner / ECS)  

---

## ğŸ“Š Artifacts & Logs
- `Artifacts/` â†’ Saved datasets, transformed data, preprocessing objects, trained models  
- `logs/` â†’ Timestamped training logs  
- `mlflow.db` â†’ MLflow experiment tracking database  

---

## ğŸ› ï¸ Tech Stack
- **Python 3.10+**  
- Pandas, NumPy, Scikit-learn (ML pipeline)  
- FastAPI (web app & API)  
- MongoDB (storage)  
- Docker (containerization)  
- AWS (ECR, S3, ECS) (deployment & storage)  
- GitHub Actions (CI/CD)  

---

## ğŸ“Œ To-Do / Future Improvements
- [ ] Add unit tests for components  
- [ ] Improve web UI for predictions  
- [ ] Add explainability (SHAP/LIME)  
- [ ] Automate dataset updates from phishing feeds  
- [ ] Add monitoring for false positives/negatives  
